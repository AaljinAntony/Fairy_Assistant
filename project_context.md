PROJECT: FAIRY ASSISTANT (LINUX LOCAL EDITION)Version: 3.1.0 (Ubuntu 24.04 Optimized)Type: Privacy-First AI AgentEnvironment: Ubuntu 24.04 (Host) + Android (Client)Language: Python 3.10+ (Backend), Dart (Mobile)1. HIGH-LEVEL OBJECTIVEBuild "Fairy," a personal AI operating system that runs entirely on local hardware.Privacy: No data leaves the local network.Intelligence: Powered by Ollama (Llama 3.2 / Mistral) running on the host PC.Hearing: Powered by OpenAI Whisper running locally on the host PC.Interface: A custom Flutter app for voice input and text output.2. SYSTEM ARCHITECTUREA. The Brain (Linux Host)OS Requirement: Ubuntu 24.04 running on Xorg (X11).CRITICAL: Automation tools (xdotool, pyautogui) do not work on Wayland.Runtime: Python main.py using Flask-SocketIO (Async Mode).Server: WebSocket server listening on 0.0.0.0:5000.Inference Engine: - LLM: ollama library interacting with local model.STT: openai-whisper (Base model) using CPU/GPU.Memory: chromadb (Persistent Vector Store) saved to ./memory_db.B. The Hands (Android - Custom App)Framework: Flutter (Dart).Functionality:Socket Client: Maintains a persistent WebSocket connection to the PC.Audio Streamer: Records audio (Push-to-Talk) and uploads raw bytes to the audio_command event.Actuator: Listens for server_action events to trigger native Android Intents (SMS, Phone, Apps).3. DIRECTORY STRUCTUREFairy_Assistant/
├── .venv/                  # Python Virtual Environment
├── .env                    # Config (e.g., MODEL_NAME="llama3.2")
├── requirements.txt        # Python dependencies
├── main.py                 # SocketIO Server & Event Loop
├── memory_brain.py         # ChromaDB wrapper
├── action_parser.py        # Logic to parse [ACTION] tags
├── tools/
│   ├── linux_ops.py        # Desktop automation (X11/subprocess)
│   └── android_ops.py      # SocketIO Emitters
├── mobile_app/             # Flutter Project
│   ├── lib/main.dart
│   └── pubspec.yaml
├── context/
│   └── ai_context.md       # Persona & Few-Shot Prompts
└── project_context.md      # THIS FILE
4. INTER-PROCESS COMMUNICATION (Socket.IO)A. Eventsclient_command: Android -> PC (User typed text).audio_command: Android -> PC (Raw audio bytes, usually WAV or PCM).server_action: PC -> Android (JSON payload).Action Types: - speak (Text-to-Speech string).transcript (STT text for UI display).log (Debug info).trigger_intent (Hardware control).B. Action Tags & HandlersThe LLM outputs tags. action_parser.py executes them.IntentOutput TagHandler LogicSystem CommandOpen App`[ACTION: OPEN_LINUXapp]`linux_ops.pyType`[ACTION: TYPE_LINUXtext]`linux_ops.pyLock`[ACTION: SYSTEM_LINUXlock]`linux_ops.pyMute`[ACTION: SYSTEM_LINUXmute]`linux_ops.pyMsg Phone`[ACTION: ANDROID_MSG...]`android_ops.py5. DEPENDENCIES & REQUIREMENTSA. System Packages (Ubuntu/Debian)Install via sudo apt install:python3-venv, python3-devxdotool (Required for window focus/typing)scrot (Required for screenshots/vision)libasound2-dev, portaudio19-dev (Required for PyAudio/Whisper)ffmpeg (Required for audio conversion)B. Python Libraries (pip)flask, flask-socketio, eventlet (Server)ollama (Local LLM)openai-whisper, torch, numpy (Local STT)chromadb (Memory)pyautogui, python-xlib (Automation)python-dotenvC. Flutter Packages (pubspec.yaml)socket_io_client: ^3.0.0record: ^5.0.0 (Audio capture)path_provider: ^2.1.0permission_handler: ^11.0.0url_launcher: ^6.2.0 (For opening WhatsApp/Maps)flutter_sms: ^2.3.36. DEVELOPMENT PHASESEnvironment Setup: - Switch Ubuntu to Xorg.Install system packages (apt).Create .venv and install requirements.txt.Brain Logic: - Implement main.py with ask_local_llm (Ollama) and transcribe_audio (Whisper).Linux Hands: - Implement tools/linux_ops.py ensuring DISPLAY=:0 is handled.Mobile App: - Create Flutter UI with a "Hold to Talk" button.Implement audio file streaming to SocketIO.Integration: - Test voice command -> Whisper -> Ollama -> Linux Action.
